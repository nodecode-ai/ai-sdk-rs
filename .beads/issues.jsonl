{"id":"ai-sdk-rs-1ku","title":"Expand Google/Vertex parity regression suite","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: google-vertex-parity-regression-suite\ntask: Add cross-provider parity assertions for shared paths to detect future divergence after consolidation.\nintegration points touched: ip-google-stack-consolidation\nwhy: n/a\n\n### deliverables\n- Parity tests across shared Google/Vertex request and stream behaviors\n- Coverage for provider-option scope and thought-signature metadata differences\n\n### acceptance\n- Regression tests fail on intentional divergence and pass on aligned behavior\n- CI-visible safety net for future refactors\n\n### dependency intent\n- google-vertex-language-model-core\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":1,"issue_type":"task","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.463388724-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.463388724-08:00","labels":["google","parity","tests"],"dependencies":[{"issue_id":"ai-sdk-rs-1ku","depends_on_id":"ai-sdk-rs-r9t","type":"blocks","created_at":"2026-02-13T18:25:44.766416983-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-2v2","title":"Normalize path-based module boundaries incrementally","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: module-boundary-normalization-slice\ntask: Reduce path-indirection in crate wiring to improve ownership clarity and coupling analyzability while keeping public exports stable.\nintegration points touched: ip-module-boundary-normalization\nwhy: Current path-mod setup obscures boundary metrics and increases maintenance complexity.\n\n### deliverables\n- Incremental boundary normalization plan executed for one stable slice\n- Updated docs/comments on module boundary ownership\n\n### acceptance\n- Public-facing module access paths remain stable\n- Tooling warnings related to unresolved path modules are reduced for the slice\n\n### dependency intent\n- provider-error-mapper-unification\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":3,"issue_type":"chore","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.716021837-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.716021837-08:00","labels":["architecture","maintainability"],"dependencies":[{"issue_id":"ai-sdk-rs-2v2","depends_on_id":"ai-sdk-rs-ke2","type":"blocks","created_at":"2026-02-13T18:25:45.0205819-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-2zp","title":"Run quant coupling and LOC gates for each refactor slice","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: quant-gate-after-each-slice\ntask: Enforce per-slice quant_metrics snapshot/compare and reject any slice that regresses coupling gate verdict.\nintegration points touched: ip-openai-failure-semantics, ip-transport-init-fallibility, ip-google-stack-consolidation, ip-provider-bootstrap-dedupe, ip-error-mapping-unification, ip-module-boundary-normalization\nwhy: Maintains hard no-regression architecture safety while deleting code.\n\n### deliverables\n- Before/after snapshot artifacts per accepted slice\n- Gate verdict log for all slices\n\n### acceptance\n- All accepted slices show compare verdict improves or no-regression\n- No slice merged without quantitative checkpoint evidence\n\n### dependency intent\n- openai-nonstream-error-gate\n- openai-stream-failed-finish-fix\n- reqwest-init-failure-tests\n- google-vertex-parity-regression-suite\n- module-boundary-normalization-slice\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":0,"issue_type":"task","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:25:32.764723306-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:25:32.764723306-08:00","labels":["coupling","gate","metrics","quality-gate"],"dependencies":[{"issue_id":"ai-sdk-rs-2zp","depends_on_id":"ai-sdk-rs-4kn","type":"blocks","created_at":"2026-02-13T18:25:45.113637566-08:00","created_by":"pomterre"},{"issue_id":"ai-sdk-rs-2zp","depends_on_id":"ai-sdk-rs-mpj","type":"blocks","created_at":"2026-02-13T18:25:45.212238377-08:00","created_by":"pomterre"},{"issue_id":"ai-sdk-rs-2zp","depends_on_id":"ai-sdk-rs-gsu","type":"blocks","created_at":"2026-02-13T18:25:45.309112023-08:00","created_by":"pomterre"},{"issue_id":"ai-sdk-rs-2zp","depends_on_id":"ai-sdk-rs-1ku","type":"blocks","created_at":"2026-02-13T18:25:45.400746072-08:00","created_by":"pomterre"},{"issue_id":"ai-sdk-rs-2zp","depends_on_id":"ai-sdk-rs-2v2","type":"blocks","created_at":"2026-02-13T18:25:45.495852395-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-4kn","title":"Enforce non-stream OpenAI top-level error handling","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: openai-nonstream-error-gate\ntask: Update do_generate response handling so top-level error payloads return SdkError instead of GenerateResponse success.\nintegration points touched: ip-openai-failure-semantics\nwhy: Addresses highest-severity correctness risk in request lifecycle.\n\n### deliverables\n- Non-stream error-path guard with parity-aligned mapping\n- Updated tests validating returned error behavior\n\n### acceptance\n- Top-level error response no longer yields success payload\n- Existing success-path behavior unchanged\n\n### dependency intent\n- openai-failure-char-tests\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=codex picked-at=2026-02-14T02:30:36Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-4kn.lock","status":"in_progress","priority":0,"issue_type":"bug","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:55.914559288-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:30:37.149956745-08:00","labels":["fragility","openai","parity"],"dependencies":[{"issue_id":"ai-sdk-rs-4kn","depends_on_id":"ai-sdk-rs-qw4","type":"blocks","created_at":"2026-02-13T18:25:44.398618151-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-62d","title":"Add regression tests for nested usage detail mapping","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: test-usage-nested-details-mapping\ntask: Add failing regression tests that assert mapping of input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens in non-stream and stream finish outputs.\nintegration points touched: ip-usage-details\nwhy: n/a\n\n### deliverables\n- Non-stream usage assertions in responses_language_model_tests.rs\n- Stream finish usage assertions in stream_fixture_tests.rs\n\n### acceptance\n- Tests fail on current behavior where nested details are not fully mapped\n- Tests are fixture-based and do not hit network\n\n### dependency intent\n- openai-parity-gap-matrix\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2349549 picked-at=2026-02-14T02:13:40Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-62d.lock","status":"closed","priority":1,"issue_type":"task","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.237686513-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:20:25.086942695-08:00","closed_at":"2026-02-13T18:20:25.086942695-08:00","close_reason":"Added failing regression assertions for nested usage detail mapping in non-stream generate and stream finish paths","labels":["openai","parity","tests","usage"],"dependencies":[{"issue_id":"ai-sdk-rs-62d","depends_on_id":"ai-sdk-rs-8uf","type":"blocks","created_at":"2026-02-13T18:02:43.923625414-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-7jd","title":"Align response.failed stream finish semantics with TS","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: fix-stream-response-failed-finish\ntask: Adjust OpenAI Responses streaming parser/mapper so response.failed and error trajectories emit parity-aligned finish reason behavior.\nintegration points touched: ip-stream-failed-finish\nwhy: n/a\n\n### deliverables\n- Code updates in OpenAI stream chunk parsing and/or mapper finish logic\n- Updated comments explaining failed/error terminal semantics\n\n### acceptance\n- Stream response.failed regression test passes\n- Existing stream fixture suite continues to pass\n\n### dependency intent\n- test-stream-response-failed-finish\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2416100 picked-at=2026-02-14T02:29:58Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-7jd.lock","status":"in_progress","priority":0,"issue_type":"bug","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.191999293-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:29:58.800470301-08:00","labels":["bugfix","openai","parity","stream"],"dependencies":[{"issue_id":"ai-sdk-rs-7jd","depends_on_id":"ai-sdk-rs-9jf","type":"blocks","created_at":"2026-02-13T18:02:43.884111236-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-7td","title":"Implement nested usage detail parity mapping","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: fix-usage-nested-details-mapping\ntask: Update usage parsing/event mapping to preserve cached and reasoning token details in normalized usage outputs for generate and stream paths.\nintegration points touched: ip-usage-details\nwhy: n/a\n\n### deliverables\n- Code updates in OpenAI usage parsing and/or core event mapping\n- Reasoning token and cached token fields populated in normalized usage\n\n### acceptance\n- Nested usage detail regression tests pass\n- No unrelated provider usage tests regress\n\n### dependency intent\n- test-usage-nested-details-mapping\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2424230 picked-at=2026-02-14T02:30:35Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-7td.lock","status":"in_progress","priority":0,"issue_type":"bug","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.288647675-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:30:35.886951066-08:00","labels":["bugfix","openai","parity","usage"],"dependencies":[{"issue_id":"ai-sdk-rs-7td","depends_on_id":"ai-sdk-rs-62d","type":"blocks","created_at":"2026-02-13T18:02:43.972007109-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-8uf","title":"Codify OpenAI Responses parity gap matrix and fixture mapping","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: openai-parity-gap-matrix\ntask: Create a short matrix mapping each identified parity gap to target Rust files, TS baseline lines, and required fixtures/tests so subsequent beads can execute without external context.\nintegration points touched: ip-nonstream-response-error, ip-stream-failed-finish, ip-usage-details, ip-function-tool-strict\nwhy: Front-loading an explicit parity matrix prevents ambiguous implementation and preserves plan intent if context is lost.\n\n### deliverables\n- Gap-to-file mapping note with Rust and TS references\n- Fixture/test inventory for each gap\n\n### acceptance\n- Each integration point has explicit target files and expected behavior\n- Each downstream bead can be executed using only bead description\n\n### dependency intent\n- none\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2322790 picked-at=2026-02-14T02:04:24Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-8uf.lock","status":"closed","priority":1,"issue_type":"task","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:04.999827916-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:09:39.463114799-08:00","closed_at":"2026-02-13T18:09:39.463114799-08:00","close_reason":"Added OpenAI Responses parity gap matrix with Rust/TS references and fixture/test mapping in docs/plans/openai-responses-parity-gap-matrix.md","labels":["openai","parity","planning"]}
{"id":"ai-sdk-rs-9jf","title":"Add stream regression test for response.failed finish behavior","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: test-stream-response-failed-finish\ntask: Add a failing stream fixture regression that asserts finish reason/terminal parts for response.failed and error chunks match TS baseline expectations.\nintegration points touched: ip-stream-failed-finish\nwhy: Finish reason drift is subtle and must be pinned with explicit terminal-stream assertions.\n\n### deliverables\n- New assertions in crates/providers/openai/tests/stream_fixture_tests.rs\n- Validation of terminal finish reason and metadata for openai-error fixture\n\n### acceptance\n- Test fails against current response.failed handling\n- Expected outcome is explicitly documented in assertion messages\n\n### dependency intent\n- openai-parity-gap-matrix\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2343495 picked-at=2026-02-14T02:11:37Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-9jf.lock","status":"closed","priority":1,"issue_type":"task","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.146023297-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:18:34.789063853-08:00","closed_at":"2026-02-13T18:18:34.789063853-08:00","close_reason":"Added stream error regression assertions for terminal finish reason/order and provider metadata parity against TS baseline (openai-error.1).","labels":["openai","parity","stream","tests"],"dependencies":[{"issue_id":"ai-sdk-rs-9jf","depends_on_id":"ai-sdk-rs-8uf","type":"blocks","created_at":"2026-02-13T18:02:43.844327938-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-9vu","title":"Extract shared provider bootstrap scaffold","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: provider-bootstrap-shared-scaffold\ntask: Introduce shared helper scaffolding for repeated provider builder flows (header filtering, defaults extraction, transport config wiring).\nintegration points touched: ip-provider-bootstrap-dedupe\nwhy: Reduces copy-paste fragility and makes future providers cheaper to add.\n\n### deliverables\n- Reusable bootstrap helpers\n- Refactored provider builders using common scaffold\n\n### acceptance\n- No behavior change in credential/env/header precedence\n- Provider registry build paths remain intact\n\n### dependency intent\n- google-vertex-shared-primitives\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":2,"issue_type":"feature","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.551099936-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.551099936-08:00","labels":["architecture","loc-reduction","providers"],"dependencies":[{"issue_id":"ai-sdk-rs-9vu","depends_on_id":"ai-sdk-rs-bfg","type":"blocks","created_at":"2026-02-13T18:25:44.856024169-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-aaa","title":"Make Reqwest transport initialization fallible","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: reqwest-transport-fallible-init\ntask: Replace panic-based reqwest client build path with recoverable initialization error handling and propagate through call sites.\nintegration points touched: ip-transport-init-fallibility\nwhy: Avoids process aborts in SDK runtime setup paths.\n\n### deliverables\n- Fallible transport constructor path\n- Adjusted call sites or compatibility wrapper with explicit error behavior\n\n### acceptance\n- No panic on client-build failure path\n- Initialization failure surfaces as typed SDK/transport error\n\n### dependency intent\n- none\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2415832 picked-at=2026-02-14T02:29:54Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-aaa.lock","status":"closed","priority":1,"issue_type":"task","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.084351939-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:34:36.139782303-08:00","closed_at":"2026-02-13T18:34:36.139782303-08:00","close_reason":"Reqwest transport now exposes fallible init (try_new) and provider bootstrap call sites propagate initialization failures as SdkError::Transport instead of panicking.","labels":["fragility","transport"]}
{"id":"ai-sdk-rs-bfg","title":"Extract shared Google/Vertex primitives","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: google-vertex-shared-primitives\ntask: Consolidate duplicated error/options/prompt/prepare_tools modules into shared primitives with provider-specific adapters.\nintegration points touched: ip-google-stack-consolidation\nwhy: Largest low-risk duplicate surface for immediate LOC reduction.\n\n### deliverables\n- Shared primitives for prompt/options/tool-prep/error mapping\n- Provider adapters preserving google vs google-vertex scope differences\n\n### acceptance\n- Duplicate files are removed or reduced significantly\n- Provider behavior remains parity-equivalent in tests\n\n### dependency intent\n- none\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":1,"issue_type":"feature","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.321291139-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.321291139-08:00","labels":["architecture","google","loc-reduction"]}
{"id":"ai-sdk-rs-gsu","title":"Add transport init failure regression tests","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: reqwest-init-failure-tests\ntask: Add focused tests that assert fallible transport setup behavior and absence of panic in failure scenarios.\nintegration points touched: ip-transport-init-fallibility\nwhy: n/a\n\n### deliverables\n- Regression tests for transport init failure semantics\n- Test notes documenting expected recoverability behavior\n\n### acceptance\n- Tests validate non-panicking behavior\n- Error class and message assertions are stable\n\n### dependency intent\n- reqwest-transport-fallible-init\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":1,"issue_type":"task","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.222602901-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.222602901-08:00","labels":["tests","transport"],"dependencies":[{"issue_id":"ai-sdk-rs-gsu","depends_on_id":"ai-sdk-rs-aaa","type":"blocks","created_at":"2026-02-13T18:25:44.580550823-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-h3z","title":"Add regression test for do_generate response.error handling","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: test-do-generate-response-error\ntask: Add a failing regression test asserting OpenAI do_generate returns an error when response.error is present, using existing offline error fixtures.\nintegration points touched: ip-nonstream-response-error\nwhy: Locks expected behavior before implementation changes and prevents silent regressions.\n\n### deliverables\n- New/updated test in crates/providers/openai/tests/responses_language_model_tests.rs\n- Assertion that generation path throws/returns SdkError on response.error\n\n### acceptance\n- Test fails on current behavior and encodes TS parity expectation\n- Test is fixture-based and deterministic\n\n### dependency intent\n- openai-parity-gap-matrix\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2338613 picked-at=2026-02-14T02:10:26Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-h3z.lock","status":"closed","priority":1,"issue_type":"task","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.050432674-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:13:15.107245345-08:00","closed_at":"2026-02-13T18:13:15.107245345-08:00","close_reason":"Added fixture-based failing regression test for do_generate response.error propagation","labels":["openai","parity","tests"],"dependencies":[{"issue_id":"ai-sdk-rs-h3z","depends_on_id":"ai-sdk-rs-8uf","type":"blocks","created_at":"2026-02-13T18:02:43.758212661-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-jmd","title":"Implement function tool strict passthrough in OpenAI requests","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: fix-function-tool-strict-passthrough\ntask: Extend relevant Rust types and OpenAI request builder serialization to preserve function tool strict mode exactly when provided.\nintegration points touched: ip-function-tool-strict\nwhy: n/a\n\n### deliverables\n- Type/model update for strict support where needed\n- OpenAI request serialization update to include strict when present\n\n### acceptance\n- Strict passthrough request-body tests pass\n- No breakage in existing function tool serialization tests\n\n### dependency intent\n- test-function-tool-strict-passthrough\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":0,"issue_type":"feature","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.388440132-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:02:05.388440132-08:00","labels":["openai","parity","serialization"],"dependencies":[{"issue_id":"ai-sdk-rs-jmd","depends_on_id":"ai-sdk-rs-vvn","type":"blocks","created_at":"2026-02-13T18:02:44.057154265-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-ke2","title":"Unify provider error mapper fallback behavior","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: provider-error-mapper-unification\ntask: Centralize common transport HttpStatus fallback mapping and preserve provider-specific body parsing hooks.\nintegration points touched: ip-error-mapping-unification\nwhy: Current fragmented mappers produce inconsistent diagnostics and duplicate code.\n\n### deliverables\n- Shared fallback mapper path\n- Provider-specific parser hooks retained for message extraction\n\n### acceptance\n- Fallback diagnostics are consistent across providers\n- Existing provider-specific parsed errors are preserved\n\n### dependency intent\n- provider-bootstrap-shared-scaffold\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":2,"issue_type":"feature","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.630375479-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.630375479-08:00","labels":["architecture","errors","ux"],"dependencies":[{"issue_id":"ai-sdk-rs-ke2","depends_on_id":"ai-sdk-rs-9vu","type":"blocks","created_at":"2026-02-13T18:25:44.941027972-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-mpj","title":"Align OpenAI failed-stream finish semantics","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: openai-stream-failed-finish-fix\ntask: Adjust stream mapping so response.failed and related error events emit parity-aligned finish semantics and metadata.\nintegration points touched: ip-openai-failure-semantics\nwhy: Failed streams currently risk being treated as normal completion.\n\n### deliverables\n- Stream event/finish mapping changes for failed trajectories\n- Fixture assertions for finish reason and error emissions\n\n### acceptance\n- openai-error stream fixture validates expected finish semantics\n- No regressions in normal completed/incomplete stream paths\n\n### dependency intent\n- openai-failure-char-tests\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":0,"issue_type":"bug","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.000120786-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.000120786-08:00","labels":["fragility","openai","streaming"],"dependencies":[{"issue_id":"ai-sdk-rs-mpj","depends_on_id":"ai-sdk-rs-qw4","type":"blocks","created_at":"2026-02-13T18:25:44.48842796-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-pfo","title":"Implement do_generate response.error propagation parity","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: fix-do-generate-response-error\ntask: Update OpenAI Responses non-stream path to detect response.error and return mapped error instead of normal content.\nintegration points touched: ip-nonstream-response-error\nwhy: n/a\n\n### deliverables\n- Code change in crates/providers/openai/src/responses/language_model.rs\n- Any required error mapping helper adjustments\n\n### acceptance\n- Regression test for response.error handling passes\n- No unrelated non-stream OpenAI tests regress\n\n### dependency intent\n- test-do-generate-response-error\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2380759 picked-at=2026-02-14T02:23:01Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-pfo.lock","status":"closed","priority":0,"issue_type":"bug","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.094327796-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:57.261976317-08:00","closed_at":"2026-02-13T18:24:57.261976317-08:00","close_reason":"do_generate now surfaces top-level response.error as SdkError::Upstream(status=400) before content extraction, matching TS non-stream parity.","labels":["bugfix","openai","parity"],"dependencies":[{"issue_id":"ai-sdk-rs-pfo","depends_on_id":"ai-sdk-rs-h3z","type":"blocks","created_at":"2026-02-13T18:02:43.800908596-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-qw4","title":"Characterize OpenAI failure semantics with regression fixtures","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: openai-failure-char-tests\ntask: Codify current non-stream and stream failure trajectories as characterization tests and expected parity assertions before behavior edits.\nintegration points touched: ip-openai-failure-semantics\nwhy: Prevents accidental behavior drift while fixing known fragility.\n\n### deliverables\n- Fixture-backed tests covering top-level response.error and response.failed stream paths\n- Documented expected finish/error mapping semantics\n\n### acceptance\n- Tests fail on current known-bad behavior and pass when corrected\n- Assertions cover both do_generate and do_stream trajectories\n\n### dependency intent\n- none\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2386956 picked-at=2026-02-14T02:25:22Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-qw4.lock","status":"closed","priority":0,"issue_type":"task","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:55.818795129-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:25:54.625419439-08:00","closed_at":"2026-02-13T18:25:54.625419439-08:00","close_reason":"Characterization coverage already present: non_stream_response_error_returns_error passes for fixed do_generate path, while stream_error_fixture still fails on known response.failed parity drift (serviceTier metadata).","labels":["fragility","openai","parity"]}
{"id":"ai-sdk-rs-r9t","title":"Consolidate Google and Vertex language-model stream core","description":"# atomic bead\n\n## full plan snapshot\nplan title: ai-sdk-rs fragility hardening and architecture LOC reduction\nplan summary: Harden known fragility points and reduce architecture duplication in provider stacks while preserving behavior parity and preventing coupling regression.\n\n### integration points (complete map)\n- [ip-openai-failure-semantics] OpenAI failure semantics\n  purpose: Ensure non-stream and stream failure paths return correct error/finish behavior.\n  integration contract: Non-stream top-level error must not return GenerateResponse success; stream failed trajectories must emit parity-aligned finish/error semantics.\n- [ip-transport-init-fallibility] Transport initialization fallibility\n  purpose: Prevent SDK process aborts from transport client init failures.\n  integration contract: Reqwest transport initialization surfaces recoverable errors instead of panicking.\n- [ip-google-stack-consolidation] Google and Vertex stack consolidation\n  purpose: Collapse duplicated provider implementations without behavior drift.\n  integration contract: Shared code preserves provider-specific auth, options scopes, and stream normalization semantics.\n- [ip-provider-bootstrap-dedupe] Provider bootstrap deduplication\n  purpose: Reduce repeated builder/header/default-option wiring across providers.\n  integration contract: Credential/env/header precedence and endpoint defaulting remain identical per provider.\n- [ip-error-mapping-unification] Error mapping unification\n  purpose: Unify fragmented error mapping with consistent diagnostics.\n  integration contract: Provider-specific parsing remains intact while fallback diagnostics become consistent and actionable.\n- [ip-module-boundary-normalization] Module boundary normalization\n  purpose: Reduce path-based boundary indirection and improve coupling observability.\n  integration contract: Public module exposure remains stable while internal structure improves analyzability and maintainability.\n\n### global constraints\n- No behavior or functionality loss.\n- Preserve public API contracts unless explicitly approved.\n- Keep provider request/response shapes and stream-part ordering stable.\n- Do not accept any coupling regression at the workspace gate.\n- Each slice must be validated with tests and quant_metrics snapshot/compare.\n\n### definition of done\n- OpenAI failure semantics match expected non-stream and stream parity behavior.\n- Transport initialization no longer panics on client build failure paths.\n- Google and Google Vertex duplicated stacks are consolidated behind shared modules with parity maintained.\n- Provider bootstrap and error-mapping duplication are reduced with equivalent behavior.\n- Path-based module boundary debt is reduced enough for coupling metrics to remain trustworthy for future slices.\n- quant_metrics compare verdict remains improves or no-regression for accepted slices.\n\n### plan assumptions\n- Current parity gap matrix for OpenAI responses reflects active known gaps.\n- inventory-based provider registration remains required.\n- Refactors can be staged incrementally without full rewrite.\n\n### plan risks\n- Provider parity regressions caused by shared-module extraction.\n- Hidden differences between Google GenAI and Google Vertex behavior during consolidation.\n- Coupling metric fidelity is partially limited by current path-based module structure.\n\n## bead-local scope\nbead key: google-vertex-language-model-core\ntask: Refactor duplicated language_model streaming and mapping logic into shared core with provider-specific strategy hooks.\nintegration points touched: ip-google-stack-consolidation\nwhy: Major source of maintenance drift and repeated bug fixes.\n\n### deliverables\n- Shared language-model core path\n- Provider-specific strategy implementations for auth/scope/url differences\n\n### acceptance\n- Google and Vertex tests pass with shared core\n- Stream part ordering and metadata semantics remain stable\n\n### dependency intent\n- google-vertex-shared-primitives\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":1,"issue_type":"feature","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:24:56.393560524-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:24:56.393560524-08:00","labels":["architecture","loc-reduction","streaming"],"dependencies":[{"issue_id":"ai-sdk-rs-r9t","depends_on_id":"ai-sdk-rs-bfg","type":"blocks","created_at":"2026-02-13T18:25:44.68369265-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-vvn","title":"Add request serialization tests for function tool strict passthrough","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: test-function-tool-strict-passthrough\ntask: Add failing request-body serialization tests covering function tool strict=true, strict=false, and strict omitted behavior.\nintegration points touched: ip-function-tool-strict\nwhy: n/a\n\n### deliverables\n- New test cases in crates/providers/openai/tests/responses_language_model_tests.rs\n- Assertions on serialized tools[].strict field behavior\n\n### acceptance\n- Tests fail on current serialization behavior\n- Assertions cover true/false/unspecified strict scenarios\n\n### dependency intent\n- openai-parity-gap-matrix\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","notes":"[beads-claim] picked-by=mike@archlinux:2367372 picked-at=2026-02-14T02:19:04Z selector=next_unblocking.sh attempt=1 lock=/home/mike/nodecode/ai-sdk-rs/.beads/agent-picks/ai-sdk-rs-vvn.lock","status":"closed","priority":1,"issue_type":"task","assignee":"pomterre","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:05.342158217-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:22:29.601791065-08:00","closed_at":"2026-02-13T18:22:29.601791065-08:00","close_reason":"Added strict passthrough regression tests for function tools: strict=true/false must serialize and strict omitted must remain absent.","labels":["openai","parity","serialization","tests"],"dependencies":[{"issue_id":"ai-sdk-rs-vvn","depends_on_id":"ai-sdk-rs-8uf","type":"blocks","created_at":"2026-02-13T18:02:44.013149285-08:00","created_by":"pomterre"}]}
{"id":"ai-sdk-rs-zl5","title":"Run OpenAI parity regression gate and publish closure note","description":"# atomic bead\n\n## full plan snapshot\nplan title: OpenAI Responses parity remediation for ai-sdk-rs\nplan summary: Close behavior drift between ai-sdk-rs OpenAI Responses provider and /home/mike/ai by fixing non-stream error propagation, response.failed streaming finish semantics, usage detail mapping, and function tool strict passthrough, with fixture-based regression coverage.\n\n### integration points (complete map)\n- [ip-nonstream-response-error] Non-stream response.error propagation\n  purpose: Ensure do_generate fails when OpenAI response payload contains top-level response.error, matching TS provider behavior.\n  integration contract: Given a response with response.error, ai-sdk-rs must surface an error instead of returning normal content.\n- [ip-stream-failed-finish] Streaming response.failed finish semantics\n  purpose: Align response.failed/error stream terminal behavior with TS finish reason semantics.\n  integration contract: For error/failed stream trajectories, finish reason and terminal parts match TS parity expectations.\n- [ip-usage-details] Usage details normalization\n  purpose: Map nested usage detail fields (cached and reasoning token details) into normalized usage outputs.\n  integration contract: input_tokens_details.cached_tokens and output_tokens_details.reasoning_tokens are preserved in normalized usage fields.\n- [ip-function-tool-strict] Function tool strict passthrough\n  purpose: Preserve function tool strict mode when building Responses API request bodies.\n  integration contract: Function tools include strict=true/false when specified and omit strict when unspecified.\n\n### global constraints\n- Scope is existing provider only: openai responses path in ai-sdk-rs.\n- Use fixture-based tests; no live provider API calls.\n- Preserve normalized stream contract in crates/sdk-types/src/v2.rs and avoid introducing incompatible stream part shapes.\n- Keep fixes localized to OpenAI provider/core mapping paths unless type support requires shared sdk-types changes.\n\n### definition of done\n- All four parity gaps are covered by deterministic tests and passing implementations.\n- OpenAI provider targeted tests pass for both request serialization and stream normalization paths.\n- No dependency cycles exist in bead graph and execution order reflects blocker intent.\n- Final parity note lists resolved gaps and any residual risk with file-level references.\n\n### plan assumptions\n- Current TS behavior in /home/mike/ai/packages/openai/src/responses is the parity baseline.\n- OpenAI fixture corpus in crates/providers/openai/tests/fixtures is authoritative for offline validation.\n- Rust stream finish behavior should align with TS snapshots for response.failed/error trajectories.\n\n### plan risks\n- Adjusting finish semantics may affect downstream consumers that implicitly depended on previous finish reasons.\n- Adding strict support may require shared type updates that can affect other providers if not isolated.\n- Usage mapping changes could unintentionally alter reported token accounting in unrelated tests.\n\n## bead-local scope\nbead key: openai-parity-regression-gate\ntask: Run the targeted OpenAI test suite after fixes, verify all parity expectations are green, and publish a concise closure note with any residual risk or follow-up beads.\nintegration points touched: ip-nonstream-response-error, ip-stream-failed-finish, ip-usage-details, ip-function-tool-strict\nwhy: A final gate bead prevents partial completion and ensures parity outcomes are explicitly verified.\n\n### deliverables\n- Targeted test run output summary\n- Closure note with resolved gaps and any follow-up issue IDs\n\n### acceptance\n- All newly added parity regressions pass\n- Any remaining drift is tracked as explicit follow-up bead(s)\n\n### dependency intent\n- fix-do-generate-response-error\n- fix-stream-response-failed-finish\n- fix-usage-nested-details-mapping\n- fix-function-tool-strict-passthrough\n\n## execution guardrail\npreserve plan compatibility invariants while delivering only this bead's scope.\n","status":"open","priority":0,"issue_type":"task","owner":"39233499+pomterre@users.noreply.github.com","created_at":"2026-02-13T18:02:33.914578082-08:00","created_by":"pomterre","updated_at":"2026-02-13T18:02:33.914578082-08:00","labels":["gate","openai","parity"],"dependencies":[{"issue_id":"ai-sdk-rs-zl5","depends_on_id":"ai-sdk-rs-pfo","type":"blocks","created_at":"2026-02-13T18:02:44.098241908-08:00","created_by":"pomterre"},{"issue_id":"ai-sdk-rs-zl5","depends_on_id":"ai-sdk-rs-7jd","type":"blocks","created_at":"2026-02-13T18:02:44.142478335-08:00","created_by":"pomterre"},{"issue_id":"ai-sdk-rs-zl5","depends_on_id":"ai-sdk-rs-7td","type":"blocks","created_at":"2026-02-13T18:02:44.184485227-08:00","created_by":"pomterre"},{"issue_id":"ai-sdk-rs-zl5","depends_on_id":"ai-sdk-rs-jmd","type":"blocks","created_at":"2026-02-13T18:02:44.228136297-08:00","created_by":"pomterre"}]}
